{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd07f4d97f22a9a973173b012f9bc9d2a139f43a30261cf742acddd600eb9c24920",
   "display_name": "Python 3.8.8 64-bit ('learning': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "7f4d97f22a9a973173b012f9bc9d2a139f43a30261cf742acddd600eb9c24920"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Linear Model and Regularization with PySpark\n",
    "\n",
    "Linear model is one of the most simple machine learning algorithm. People often getting attracted to more advanced model such as Neural Network or Gradient Boosting due to the hype and the preditictive performance. However, on most of daily business case, building a linear model is good enough. Linear model is also comes with the benefit of being interpretable, compared to the black box Neural Network. On this occasion, we will build a linear model with the addition of regularization to analyze the data while still get a great predictive performance.\n",
    "\n",
    "## Library and Setup\n",
    "\n",
    "As part of my learning journey, I will use PySpark throughout the notebook. First, we will start the spark session and name it as `laptop_lm`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd3027681f0>"
      ],
      "text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://void:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.1.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>laptop_lm</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('laptop_lm').getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "source": [
    "The following code contains all libraries used in this notebook."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Schema\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# Spark function\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "# One-Hot Encoding\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "# Scaling\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "# Cross-Validation\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "# Machine Learning\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "source": [
    "# Case Study: Laptop Price Prediction\n",
    "\n",
    "On this occasion, we will try to understand what makes a price of a laptop to increase by building a linear model. For a computer geek or people who manufactured laptops may already now the production cost of each component. However, for a lay people like us who only know how to use the laptop, exploring this dataset and building a machine learning model around it will help us to compare laptop with various specifications and build by various companies. We may also see some intangible factors that can affect the price, such as the value of a brand like Apple or the CPU component such us Intel Core vs AMD.\n",
    "\n",
    "## Data\n",
    "\n",
    "The data come from [Laptop Company Price List](https://www.kaggle.com/muhammetvarl/laptop-price) with the following dictionary:\n",
    "\n",
    "- **Company**: Laptop Manufacturer\n",
    "- **Product**: Brand and Model\n",
    "- **TypeName**: Type (Notebook, Ultrabook, Gaming, etc.)\n",
    "- **Inches**: Screen Size\n",
    "- **ScreenResolution**: Screen Resolution\n",
    "- **Cpu**: Central Processing Unit (CPU)\n",
    "- **Ram**: Laptop RAM\n",
    "- **Memory**: Hard Disk / SSD Memory\n",
    "- **GPU**: Graphics Processing Units (GPU)\n",
    "- **OpSys**: Operating System\n",
    "- **Weight**: Laptop Weight\n",
    "- **Price_euros**: Price in Euro"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------+-------+-----------------+---------+------+--------------------+--------------------+----+-------------------+--------------------+----------+------+-----------+\n|laptop_ID|Company|          Product| TypeName|Inches|    ScreenResolution|                 Cpu| Ram|             Memory|                 Gpu|     OpSys|Weight|Price_euros|\n+---------+-------+-----------------+---------+------+--------------------+--------------------+----+-------------------+--------------------+----------+------+-----------+\n|        1|  Apple|      MacBook Pro|Ultrabook|  13.3|IPS Panel Retina ...|Intel Core i5 2.3GHz| 8GB|          128GB SSD|Intel Iris Plus G...|     macOS|1.37kg|    1339.69|\n|        2|  Apple|      Macbook Air|Ultrabook|  13.3|            1440x900|Intel Core i5 1.8GHz| 8GB|128GB Flash Storage|Intel HD Graphics...|     macOS|1.34kg|     898.94|\n|        3|     HP|           250 G6| Notebook|  15.6|   Full HD 1920x1080|Intel Core i5 720...| 8GB|          256GB SSD|Intel HD Graphics...|     No OS|1.86kg|      575.0|\n|        4|  Apple|      MacBook Pro|Ultrabook|  15.4|IPS Panel Retina ...|Intel Core i7 2.7GHz|16GB|          512GB SSD|  AMD Radeon Pro 455|     macOS|1.83kg|    2537.45|\n|        5|  Apple|      MacBook Pro|Ultrabook|  13.3|IPS Panel Retina ...|Intel Core i5 3.1GHz| 8GB|          256GB SSD|Intel Iris Plus G...|     macOS|1.37kg|     1803.6|\n|        6|   Acer|         Aspire 3| Notebook|  15.6|            1366x768|AMD A9-Series 942...| 4GB|          500GB HDD|       AMD Radeon R5|Windows 10| 2.1kg|      400.0|\n|        7|  Apple|      MacBook Pro|Ultrabook|  15.4|IPS Panel Retina ...|Intel Core i7 2.2GHz|16GB|256GB Flash Storage|Intel Iris Pro Gr...|  Mac OS X|2.04kg|    2139.97|\n|        8|  Apple|      Macbook Air|Ultrabook|  13.3|            1440x900|Intel Core i5 1.8GHz| 8GB|256GB Flash Storage|Intel HD Graphics...|     macOS|1.34kg|     1158.7|\n|        9|   Asus|  ZenBook UX430UN|Ultrabook|  14.0|   Full HD 1920x1080|Intel Core i7 855...|16GB|          512GB SSD|Nvidia GeForce MX150|Windows 10| 1.3kg|     1495.0|\n|       10|   Acer|          Swift 3|Ultrabook|  14.0|IPS Panel Full HD...|Intel Core i5 825...| 8GB|          256GB SSD|Intel UHD Graphic...|Windows 10| 1.6kg|      770.0|\n|       11|     HP|           250 G6| Notebook|  15.6|            1366x768|Intel Core i5 720...| 4GB|          500GB HDD|Intel HD Graphics...|     No OS|1.86kg|      393.9|\n|       12|     HP|           250 G6| Notebook|  15.6|   Full HD 1920x1080|Intel Core i3 600...| 4GB|          500GB HDD|Intel HD Graphics...|     No OS|1.86kg|     344.99|\n|       13|  Apple|      MacBook Pro|Ultrabook|  15.4|IPS Panel Retina ...|Intel Core i7 2.8GHz|16GB|          256GB SSD|  AMD Radeon Pro 555|     macOS|1.83kg|    2439.97|\n|       14|   Dell|    Inspiron 3567| Notebook|  15.6|   Full HD 1920x1080|Intel Core i3 600...| 4GB|          256GB SSD|  AMD Radeon R5 M430|Windows 10| 2.2kg|      498.9|\n|       15|  Apple|     MacBook 12\"\"|Ultrabook|  12.0|IPS Panel Retina ...|Intel Core M m3 1...| 8GB|          256GB SSD|Intel HD Graphics...|     macOS|0.92kg|     1262.4|\n|       16|  Apple|      MacBook Pro|Ultrabook|  13.3|IPS Panel Retina ...|Intel Core i5 2.3GHz| 8GB|          256GB SSD|Intel Iris Plus G...|     macOS|1.37kg|    1518.55|\n|       17|   Dell|    Inspiron 3567| Notebook|  15.6|   Full HD 1920x1080|Intel Core i7 750...| 8GB|          256GB SSD|  AMD Radeon R5 M430|Windows 10| 2.2kg|      745.0|\n|       18|  Apple|      MacBook Pro|Ultrabook|  15.4|IPS Panel Retina ...|Intel Core i7 2.9GHz|16GB|          512GB SSD|  AMD Radeon Pro 560|     macOS|1.83kg|     2858.0|\n|       19| Lenovo|IdeaPad 320-15IKB| Notebook|  15.6|   Full HD 1920x1080|Intel Core i3 710...| 8GB|            1TB HDD|Nvidia GeForce 940MX|     No OS| 2.2kg|      499.0|\n|       20|   Dell|           XPS 13|Ultrabook|  13.3|IPS Panel Full HD...|Intel Core i5 825...| 8GB|          128GB SSD|Intel UHD Graphic...|Windows 10|1.22kg|      979.0|\n+---------+-------+-----------------+---------+------+--------------------+--------------------+----+-------------------+--------------------+----------+------+-----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "laptop = spark.read.csv(\"data/laptop_price.csv\", header= True, inferSchema=True)\n",
    "\n",
    "# Show the first 20 rows from the data\n",
    "laptop.show()"
   ]
  },
  {
   "source": [
    "Check the type of the dataframe."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "type(laptop)"
   ]
  },
  {
   "source": [
    "You can also convert the Spark dataframe to Pandas dataframe for better visual."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   laptop_ID Company      Product   TypeName  Inches  \\\n",
       "0          1   Apple  MacBook Pro  Ultrabook    13.3   \n",
       "1          2   Apple  Macbook Air  Ultrabook    13.3   \n",
       "2          3      HP       250 G6   Notebook    15.6   \n",
       "3          4   Apple  MacBook Pro  Ultrabook    15.4   \n",
       "4          5   Apple  MacBook Pro  Ultrabook    13.3   \n",
       "\n",
       "                     ScreenResolution                         Cpu   Ram  \\\n",
       "0  IPS Panel Retina Display 2560x1600        Intel Core i5 2.3GHz   8GB   \n",
       "1                            1440x900        Intel Core i5 1.8GHz   8GB   \n",
       "2                   Full HD 1920x1080  Intel Core i5 7200U 2.5GHz   8GB   \n",
       "3  IPS Panel Retina Display 2880x1800        Intel Core i7 2.7GHz  16GB   \n",
       "4  IPS Panel Retina Display 2560x1600        Intel Core i5 3.1GHz   8GB   \n",
       "\n",
       "                Memory                           Gpu  OpSys  Weight  \\\n",
       "0            128GB SSD  Intel Iris Plus Graphics 640  macOS  1.37kg   \n",
       "1  128GB Flash Storage        Intel HD Graphics 6000  macOS  1.34kg   \n",
       "2            256GB SSD         Intel HD Graphics 620  No OS  1.86kg   \n",
       "3            512GB SSD            AMD Radeon Pro 455  macOS  1.83kg   \n",
       "4            256GB SSD  Intel Iris Plus Graphics 650  macOS  1.37kg   \n",
       "\n",
       "   Price_euros  \n",
       "0      1339.69  \n",
       "1       898.94  \n",
       "2       575.00  \n",
       "3      2537.45  \n",
       "4      1803.60  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>laptop_ID</th>\n      <th>Company</th>\n      <th>Product</th>\n      <th>TypeName</th>\n      <th>Inches</th>\n      <th>ScreenResolution</th>\n      <th>Cpu</th>\n      <th>Ram</th>\n      <th>Memory</th>\n      <th>Gpu</th>\n      <th>OpSys</th>\n      <th>Weight</th>\n      <th>Price_euros</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Apple</td>\n      <td>MacBook Pro</td>\n      <td>Ultrabook</td>\n      <td>13.3</td>\n      <td>IPS Panel Retina Display 2560x1600</td>\n      <td>Intel Core i5 2.3GHz</td>\n      <td>8GB</td>\n      <td>128GB SSD</td>\n      <td>Intel Iris Plus Graphics 640</td>\n      <td>macOS</td>\n      <td>1.37kg</td>\n      <td>1339.69</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Apple</td>\n      <td>Macbook Air</td>\n      <td>Ultrabook</td>\n      <td>13.3</td>\n      <td>1440x900</td>\n      <td>Intel Core i5 1.8GHz</td>\n      <td>8GB</td>\n      <td>128GB Flash Storage</td>\n      <td>Intel HD Graphics 6000</td>\n      <td>macOS</td>\n      <td>1.34kg</td>\n      <td>898.94</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>HP</td>\n      <td>250 G6</td>\n      <td>Notebook</td>\n      <td>15.6</td>\n      <td>Full HD 1920x1080</td>\n      <td>Intel Core i5 7200U 2.5GHz</td>\n      <td>8GB</td>\n      <td>256GB SSD</td>\n      <td>Intel HD Graphics 620</td>\n      <td>No OS</td>\n      <td>1.86kg</td>\n      <td>575.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Apple</td>\n      <td>MacBook Pro</td>\n      <td>Ultrabook</td>\n      <td>15.4</td>\n      <td>IPS Panel Retina Display 2880x1800</td>\n      <td>Intel Core i7 2.7GHz</td>\n      <td>16GB</td>\n      <td>512GB SSD</td>\n      <td>AMD Radeon Pro 455</td>\n      <td>macOS</td>\n      <td>1.83kg</td>\n      <td>2537.45</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Apple</td>\n      <td>MacBook Pro</td>\n      <td>Ultrabook</td>\n      <td>13.3</td>\n      <td>IPS Panel Retina Display 2560x1600</td>\n      <td>Intel Core i5 3.1GHz</td>\n      <td>8GB</td>\n      <td>256GB SSD</td>\n      <td>Intel Iris Plus Graphics 650</td>\n      <td>macOS</td>\n      <td>1.37kg</td>\n      <td>1803.60</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "pd.DataFrame(laptop.head(5), columns= laptop.columns)"
   ]
  },
  {
   "source": [
    "Let's check the schema or the data type of each column."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- laptop_ID: integer (nullable = true)\n |-- Company: string (nullable = true)\n |-- Product: string (nullable = true)\n |-- TypeName: string (nullable = true)\n |-- Inches: double (nullable = true)\n |-- ScreenResolution: string (nullable = true)\n |-- Cpu: string (nullable = true)\n |-- Ram: string (nullable = true)\n |-- Memory: string (nullable = true)\n |-- Gpu: string (nullable = true)\n |-- OpSys: string (nullable = true)\n |-- Weight: string (nullable = true)\n |-- Price_euros: double (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "laptop.printSchema()"
   ]
  },
  {
   "source": [
    "Some column should be numerical, such as the RAM and memory. Those columns is still in string format and have non-numeric characters. We will clean the data later before building the model.\n",
    "\n",
    "We will continue by checking the number of rows and columns from the data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of rows: 1303\nNumber of columns: 13\n"
     ]
    }
   ],
   "source": [
    "# Number of Row\n",
    "print( 'Number of rows: ' + str( laptop.count() ) )\n",
    "\n",
    "# Number of Column\n",
    "print( 'Number of columns: ' + str( len(laptop.columns) ) )"
   ]
  },
  {
   "source": [
    "Let's check if there is any duplicated data. We need to group the data with all columns and then count the number of each group. A duplicate row will have count > 1."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------+-------+-------+--------+------+----------------+---+---+------+---+-----+------+-----------+-----+\n|laptop_ID|Company|Product|TypeName|Inches|ScreenResolution|Cpu|Ram|Memory|Gpu|OpSys|Weight|Price_euros|count|\n+---------+-------+-------+--------+------+----------------+---+---+------+---+-----+------+-----------+-----+\n+---------+-------+-------+--------+------+----------------+---+---+------+---+-----+------+-----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "laptop.groupBy(laptop.columns).count().filter(\"count > 1\").show()"
   ]
  },
  {
   "source": [
    "Based on the finding, we will have 0 observation of duplicated data.\n",
    "\n",
    "Let's check if there is any missing value from each column. We can do this by substracting the number of original row with the number of rows after removing the NA."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of rows with missing value:\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "original_row = laptop.count()\n",
    "after_na = laptop.na.drop().count()\n",
    "\n",
    "print(\"Number of rows with missing value:\")\n",
    "original_row - after_na"
   ]
  },
  {
   "source": [
    "Based on the result, we find that there is no missing value in any column on our dataset.\n",
    "\n",
    "## Data Wrangling\n",
    "\n",
    "Although the information given from the dataset is quite comprehensive, we need to transform the data to a proper format to build a machine learning.\n",
    "\n",
    "### Transforming Weight\n",
    "\n",
    "The first we do is removing the weight unit (kg) from the `Weight` column and tranform the value into float/numeric."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------+-------+---------------+---------+------+--------------------+--------------------+----+-------------------+--------------------+----------+------+-----------+\n|laptop_ID|Company|        Product| TypeName|Inches|    ScreenResolution|                 Cpu| Ram|             Memory|                 Gpu|     OpSys|Weight|Price_euros|\n+---------+-------+---------------+---------+------+--------------------+--------------------+----+-------------------+--------------------+----------+------+-----------+\n|        1|  Apple|    MacBook Pro|Ultrabook|  13.3|IPS Panel Retina ...|Intel Core i5 2.3GHz| 8GB|          128GB SSD|Intel Iris Plus G...|     macOS|  1.37|    1339.69|\n|        2|  Apple|    Macbook Air|Ultrabook|  13.3|            1440x900|Intel Core i5 1.8GHz| 8GB|128GB Flash Storage|Intel HD Graphics...|     macOS|  1.34|     898.94|\n|        3|     HP|         250 G6| Notebook|  15.6|   Full HD 1920x1080|Intel Core i5 720...| 8GB|          256GB SSD|Intel HD Graphics...|     No OS|  1.86|      575.0|\n|        4|  Apple|    MacBook Pro|Ultrabook|  15.4|IPS Panel Retina ...|Intel Core i7 2.7GHz|16GB|          512GB SSD|  AMD Radeon Pro 455|     macOS|  1.83|    2537.45|\n|        5|  Apple|    MacBook Pro|Ultrabook|  13.3|IPS Panel Retina ...|Intel Core i5 3.1GHz| 8GB|          256GB SSD|Intel Iris Plus G...|     macOS|  1.37|     1803.6|\n|        6|   Acer|       Aspire 3| Notebook|  15.6|            1366x768|AMD A9-Series 942...| 4GB|          500GB HDD|       AMD Radeon R5|Windows 10|   2.1|      400.0|\n|        7|  Apple|    MacBook Pro|Ultrabook|  15.4|IPS Panel Retina ...|Intel Core i7 2.2GHz|16GB|256GB Flash Storage|Intel Iris Pro Gr...|  Mac OS X|  2.04|    2139.97|\n|        8|  Apple|    Macbook Air|Ultrabook|  13.3|            1440x900|Intel Core i5 1.8GHz| 8GB|256GB Flash Storage|Intel HD Graphics...|     macOS|  1.34|     1158.7|\n|        9|   Asus|ZenBook UX430UN|Ultrabook|  14.0|   Full HD 1920x1080|Intel Core i7 855...|16GB|          512GB SSD|Nvidia GeForce MX150|Windows 10|   1.3|     1495.0|\n|       10|   Acer|        Swift 3|Ultrabook|  14.0|IPS Panel Full HD...|Intel Core i5 825...| 8GB|          256GB SSD|Intel UHD Graphic...|Windows 10|   1.6|      770.0|\n+---------+-------+---------------+---------+------+--------------------+--------------------+----+-------------------+--------------------+----------+------+-----------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "laptop = laptop.withColumn('Weight', f.regexp_replace(laptop['Weight'], 'kg', ''))\n",
    "laptop = laptop.withColumn('Weight', laptop['Weight'].cast(DoubleType()))\n",
    "\n",
    "laptop.show(10)"
   ]
  },
  {
   "source": [
    "Check the data type after the transformation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- laptop_ID: integer (nullable = true)\n |-- Company: string (nullable = true)\n |-- Product: string (nullable = true)\n |-- TypeName: string (nullable = true)\n |-- Inches: double (nullable = true)\n |-- ScreenResolution: string (nullable = true)\n |-- Cpu: string (nullable = true)\n |-- Ram: string (nullable = true)\n |-- Memory: string (nullable = true)\n |-- Gpu: string (nullable = true)\n |-- OpSys: string (nullable = true)\n |-- Weight: double (nullable = true)\n |-- Price_euros: double (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "laptop.printSchema()"
   ]
  },
  {
   "source": [
    "Let's check if there is any missing value as a result of our data wrangling process on the `Weight` column."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of rows with missing value:\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "original_row = laptop.count()\n",
    "after_na = laptop.na.drop().count()\n",
    "\n",
    "print(\"Number of rows with missing value:\")\n",
    "original_row - after_na"
   ]
  },
  {
   "source": [
    "### Transforming RAM\n",
    "\n",
    "The next thing we do is removing the unit `GB` from the `Ram` column and transform the value into integer."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------+-------+-----------+---------+------+--------------------+--------------------+---+-------------------+--------------------+-----+------+-----------+\n|laptop_ID|Company|    Product| TypeName|Inches|    ScreenResolution|                 Cpu|Ram|             Memory|                 Gpu|OpSys|Weight|Price_euros|\n+---------+-------+-----------+---------+------+--------------------+--------------------+---+-------------------+--------------------+-----+------+-----------+\n|        1|  Apple|MacBook Pro|Ultrabook|  13.3|IPS Panel Retina ...|Intel Core i5 2.3GHz|  8|          128GB SSD|Intel Iris Plus G...|macOS|  1.37|    1339.69|\n|        2|  Apple|Macbook Air|Ultrabook|  13.3|            1440x900|Intel Core i5 1.8GHz|  8|128GB Flash Storage|Intel HD Graphics...|macOS|  1.34|     898.94|\n|        3|     HP|     250 G6| Notebook|  15.6|   Full HD 1920x1080|Intel Core i5 720...|  8|          256GB SSD|Intel HD Graphics...|No OS|  1.86|      575.0|\n|        4|  Apple|MacBook Pro|Ultrabook|  15.4|IPS Panel Retina ...|Intel Core i7 2.7GHz| 16|          512GB SSD|  AMD Radeon Pro 455|macOS|  1.83|    2537.45|\n|        5|  Apple|MacBook Pro|Ultrabook|  13.3|IPS Panel Retina ...|Intel Core i5 3.1GHz|  8|          256GB SSD|Intel Iris Plus G...|macOS|  1.37|     1803.6|\n+---------+-------+-----------+---------+------+--------------------+--------------------+---+-------------------+--------------------+-----+------+-----------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "laptop = laptop.withColumn('Ram', f.regexp_replace(laptop['Ram'], 'GB', ''))\n",
    "laptop = laptop.withColumn('Ram', laptop['Ram'].cast(IntegerType()))\n",
    "\n",
    "laptop.show(5)"
   ]
  },
  {
   "source": [
    "### Transforming Memory\n",
    "\n",
    "Now we will separate the `Memory` column into 3 different columns: SSD, HDD, and Flash based on the type of the storage system. The first thing we do is to find the specific storage type, for example SSD, and extract the value. If a laptop does not have any SSD, the value will be empty.\n",
    "\n",
    "Here I convert TB to GB by replacing the string `TB` to `000` to indicate thousand. I also remove the unit from the string and the remaining string will only consists of the memory size and the type of the memory (SSD, HDD, Flash Storage)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------+-------+-----------+---------+------+--------------------+--------------------+---+-----------------+--------------------+-----+------+-----------+\n|laptop_ID|Company|    Product| TypeName|Inches|    ScreenResolution|                 Cpu|Ram|           Memory|                 Gpu|OpSys|Weight|Price_euros|\n+---------+-------+-----------+---------+------+--------------------+--------------------+---+-----------------+--------------------+-----+------+-----------+\n|        1|  Apple|MacBook Pro|Ultrabook|  13.3|IPS Panel Retina ...|Intel Core i5 2.3GHz|  8|          128 SSD|Intel Iris Plus G...|macOS|  1.37|    1339.69|\n|        2|  Apple|Macbook Air|Ultrabook|  13.3|            1440x900|Intel Core i5 1.8GHz|  8|128 Flash Storage|Intel HD Graphics...|macOS|  1.34|     898.94|\n|        3|     HP|     250 G6| Notebook|  15.6|   Full HD 1920x1080|Intel Core i5 720...|  8|          256 SSD|Intel HD Graphics...|No OS|  1.86|      575.0|\n|        4|  Apple|MacBook Pro|Ultrabook|  15.4|IPS Panel Retina ...|Intel Core i7 2.7GHz| 16|          512 SSD|  AMD Radeon Pro 455|macOS|  1.83|    2537.45|\n|        5|  Apple|MacBook Pro|Ultrabook|  13.3|IPS Panel Retina ...|Intel Core i5 3.1GHz|  8|          256 SSD|Intel Iris Plus G...|macOS|  1.37|     1803.6|\n+---------+-------+-----------+---------+------+--------------------+--------------------+---+-----------------+--------------------+-----+------+-----------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "laptop = laptop.withColumn('Memory', f.regexp_replace(laptop['Memory'], 'TB ', '000 '))\n",
    "laptop = laptop.withColumn('Memory', f.regexp_replace(laptop['Memory'], 'GB ', ' '))\n",
    "\n",
    "laptop.show(5)"
   ]
  },
  {
   "source": [
    "The next thing is to extract how many memory of the laptop come from `SSD`. The first thing is to extract with the pattern of `\\d+.* SSD` which indicates that I only want to get numbers followed by whitespace and the word SSD. If these pattern is not found, the regex will return nothing ('') and we will replace it by `0`. We also remove the whitespace and the word SSD (` SSD`) from the string."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------+-------------------+----------+\n|laptop_ID|             Memory|       ssd|\n+---------+-------------------+----------+\n|        1|            128 SSD|       128|\n|        2|  128 Flash Storage|         0|\n|        3|            256 SSD|       256|\n|        4|            512 SSD|       512|\n|        5|            256 SSD|       256|\n|        6|            500 HDD|         0|\n|        7|  256 Flash Storage|         0|\n|        8|  256 Flash Storage|         0|\n|        9|            512 SSD|       512|\n|       10|            256 SSD|       256|\n|       11|            500 HDD|         0|\n|       12|            500 HDD|         0|\n|       13|            256 SSD|       256|\n|       14|            256 SSD|       256|\n|       15|            256 SSD|       256|\n|       16|            256 SSD|       256|\n|       17|            256 SSD|       256|\n|       18|            512 SSD|       512|\n|       19|           1000 HDD|         0|\n|       20|            128 SSD|       128|\n|       21|   32 Flash Storage|         0|\n|       22|128 SSD +  1000 HDD|       128|\n|       23|            500 HDD|         0|\n|       24|            256 SSD|       256|\n|       25|            256 SSD|       256|\n|       26|           1000 HDD|         0|\n|       27|  128 Flash Storage|         0|\n|       28|            256 SSD|       256|\n|       29| 256 SSD +  256 SSD|256 +  256|\n|       30|           1000 HDD|         0|\n+---------+-------------------+----------+\nonly showing top 30 rows\n\n"
     ]
    }
   ],
   "source": [
    "laptop = laptop.withColumn('ssd', f.regexp_extract(laptop['Memory'], '\\d+.* SSD', 0))\n",
    "laptop = laptop.withColumn('ssd', f.regexp_replace(laptop['ssd'], ' SSD', ''))\n",
    "laptop = laptop.withColumn('ssd', f.when(laptop['ssd'] == '', '0').otherwise(laptop['ssd']))\n",
    "\n",
    "laptop.select(['laptop_ID', 'Memory', 'ssd']).show(30)"
   ]
  },
  {
   "source": [
    "You may have notice from the above table, on the 29th rows there is an SSD with the string `256 + 256` which means that the laptop come with 2 separate SSD. We will sum the memory to get the total memory while also converting all the string into numeric type."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------+-------------------+-----+\n|laptop_ID|             Memory|  ssd|\n+---------+-------------------+-----+\n|        1|            128 SSD|128.0|\n|        2|  128 Flash Storage|  0.0|\n|        3|            256 SSD|256.0|\n|        4|            512 SSD|512.0|\n|        5|            256 SSD|256.0|\n|        6|            500 HDD|  0.0|\n|        7|  256 Flash Storage|  0.0|\n|        8|  256 Flash Storage|  0.0|\n|        9|            512 SSD|512.0|\n|       10|            256 SSD|256.0|\n|       11|            500 HDD|  0.0|\n|       12|            500 HDD|  0.0|\n|       13|            256 SSD|256.0|\n|       14|            256 SSD|256.0|\n|       15|            256 SSD|256.0|\n|       16|            256 SSD|256.0|\n|       17|            256 SSD|256.0|\n|       18|            512 SSD|512.0|\n|       19|           1000 HDD|  0.0|\n|       20|            128 SSD|128.0|\n|       21|   32 Flash Storage|  0.0|\n|       22|128 SSD +  1000 HDD|128.0|\n|       23|            500 HDD|  0.0|\n|       24|            256 SSD|256.0|\n|       25|            256 SSD|256.0|\n|       26|           1000 HDD|  0.0|\n|       27|  128 Flash Storage|  0.0|\n|       28|            256 SSD|256.0|\n|       29| 256 SSD +  256 SSD|512.0|\n|       30|           1000 HDD|  0.0|\n+---------+-------------------+-----+\nonly showing top 30 rows\n\n"
     ]
    }
   ],
   "source": [
    "laptop = laptop.withColumn('ssd', f.when( f.col('ssd').contains('+'), \n",
    "    f.trim(f.regexp_extract(laptop['ssd'], '\\d+ ', 0)).cast(DoubleType()) + f.trim(f.regexp_extract(laptop['ssd'], ' \\d+', 0)).cast(DoubleType()) ).\\\n",
    "        otherwise(laptop['ssd'].cast(DoubleType()))\n",
    "        ) \n",
    "\n",
    "laptop.select(['laptop_ID', 'Memory', 'ssd']).show(30)"
   ]
  },
  {
   "source": [
    "Check the schema or the data type of each column."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- laptop_ID: integer (nullable = true)\n |-- Company: string (nullable = true)\n |-- Product: string (nullable = true)\n |-- TypeName: string (nullable = true)\n |-- Inches: double (nullable = true)\n |-- ScreenResolution: string (nullable = true)\n |-- Cpu: string (nullable = true)\n |-- Ram: integer (nullable = true)\n |-- Memory: string (nullable = true)\n |-- Gpu: string (nullable = true)\n |-- OpSys: string (nullable = true)\n |-- Weight: double (nullable = true)\n |-- Price_euros: double (nullable = true)\n |-- ssd: double (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "laptop.printSchema()"
   ]
  },
  {
   "source": [
    "We will do the same thing with the HDD and Flash Storage."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------+-----------------+-----+-----+-----+\n|laptop_ID|           Memory|  ssd|  hdd|flash|\n+---------+-----------------+-----+-----+-----+\n|        1|          128 SSD|128.0|  0.0|  0.0|\n|        2|128 Flash Storage|  0.0|  0.0|128.0|\n|        3|          256 SSD|256.0|  0.0|  0.0|\n|        4|          512 SSD|512.0|  0.0|  0.0|\n|        5|          256 SSD|256.0|  0.0|  0.0|\n|        6|          500 HDD|  0.0|500.0|  0.0|\n|        7|256 Flash Storage|  0.0|  0.0|256.0|\n|        8|256 Flash Storage|  0.0|  0.0|256.0|\n|        9|          512 SSD|512.0|  0.0|  0.0|\n|       10|          256 SSD|256.0|  0.0|  0.0|\n+---------+-----------------+-----+-----+-----+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "# HDD Storage\n",
    "laptop = laptop.withColumn('hdd', f.regexp_extract(laptop['Memory'], '\\d+.* HDD', 0))\n",
    "laptop = laptop.withColumn('hdd', f.regexp_replace(laptop['hdd'], ' HDD', ''))\n",
    "laptop = laptop.withColumn('hdd', f.when(laptop['hdd'] == '', '0').otherwise(laptop['hdd']))\n",
    "laptop = laptop.withColumn('hdd', f.when( f.col('hdd').contains('+'), \n",
    "    f.rtrim(f.regexp_extract(laptop['hdd'], '\\d+ ', 0)).cast(DoubleType()) + f.ltrim(f.regexp_extract(laptop['hdd'], ' \\d+', 0)).cast(DoubleType()) ).\\\n",
    "        otherwise(laptop['hdd'].cast(DoubleType()))\n",
    "        ) \n",
    "\n",
    "# Flash Storage\n",
    "laptop = laptop.withColumn('flash', f.regexp_extract(laptop['Memory'], '\\d+.* Flash', 0))\n",
    "laptop = laptop.withColumn('flash', f.regexp_replace(laptop['flash'], ' Flash', ''))\n",
    "laptop = laptop.withColumn('flash', f.when(laptop['flash'] == '', '0').otherwise(laptop['flash']))\n",
    "laptop = laptop.withColumn('flash', f.when( f.col('flash').contains('+'), \n",
    "    f.rtrim(f.regexp_extract(laptop['flash'], '\\d+ ', 0)).cast(DoubleType()) + f.ltrim(f.regexp_extract(laptop['flash'], ' \\d+', 0)).cast(DoubleType()) ).\\\n",
    "        otherwise(laptop['flash'].cast(DoubleType()))\n",
    "        ) \n",
    "\n",
    "laptop.select(['laptop_ID', 'Memory', 'ssd', 'hdd', 'flash']).show(10)"
   ]
  },
  {
   "source": [
    "### Transforming CPU\n",
    "\n",
    "The next thing we do is transforming the `Cpu` column. We will separate the processor type and the processor clock speed.\n",
    "\n",
    "The processor clock speed is indicated by the number followed by the GigaHertz (GHz) unit. Let's check the number of CPU type and their respective frequency of data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "laptop.groupBy('Cpu').count().sort(f.col('count').desc()).show(truncate = False)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------------------------------------+-----+\n|Cpu                                 |count|\n+------------------------------------+-----+\n|Intel Core i5 7200U 2.5GHz          |190  |\n|Intel Core i7 7700HQ 2.8GHz         |146  |\n|Intel Core i7 7500U 2.7GHz          |134  |\n|Intel Core i7 8550U 1.8GHz          |73   |\n|Intel Core i5 8250U 1.6GHz          |72   |\n|Intel Core i5 6200U 2.3GHz          |68   |\n|Intel Core i3 6006U 2GHz            |64   |\n|Intel Core i7 6500U 2.5GHz          |49   |\n|Intel Core i7 6700HQ 2.6GHz         |43   |\n|Intel Core i3 7100U 2.4GHz          |37   |\n|Intel Core i5 7300HQ 2.5GHz         |33   |\n|Intel Celeron Dual Core N3350 1.1GHz|30   |\n|Intel Celeron Dual Core N3060 1.6GHz|28   |\n|Intel Core i7 6600U 2.6GHz          |18   |\n|Intel Core i3 6006U 2.0GHz          |16   |\n|Intel Core i5 7300U 2.6GHz          |14   |\n|Intel Pentium Quad Core N4200 1.1GHz|14   |\n|Intel Core i7 7600U 2.8GHz          |13   |\n|Intel Core i5 6300U 2.4GHz          |11   |\n|Intel Celeron Dual Core N3050 1.6GHz|11   |\n+------------------------------------+-----+\nonly showing top 20 rows\n\n"
     ]
    }
   ]
  },
  {
   "source": [
    "To simplify the processor/CPU type and prevent us from getting to many categorical class, we will only consider the general type only. For example, `Intel Core i5` and `Intel Core i5 7200U` will be considered as the same type of CPU. Let's check the result of the CPU type name cleansing process. We expect a general CPU type and try not to be to specific to reduce number of new features."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------------------+-----+\n|cpu_type               |count|\n+-----------------------+-----+\n|Intel Core i7          |527  |\n|Intel Core i5          |423  |\n|Intel Core i3          |136  |\n|Intel Celeron Dual Core|80   |\n|AMD                    |47   |\n|Intel Pentium Quad Core|27   |\n|Intel Core M           |16   |\n|Intel Atom x5          |10   |\n|AMD E                  |9    |\n|Intel Celeron Quad Core|8    |\n|AMD Ryzen              |4    |\n|Intel Xeon             |4    |\n|Intel Atom             |3    |\n|Intel Pentium Dual Core|3    |\n|Intel Core M m3        |2    |\n|AMD FX                 |2    |\n|Samsung Cortex         |1    |\n|Intel Core M m7        |1    |\n+-----------------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "laptop = laptop.withColumn('cpu_type', f.regexp_extract(laptop['Cpu'], '.*? \\d+', 0))\n",
    "laptop = laptop.withColumn('cpu_type', f.regexp_replace(laptop['cpu_type'], ' \\d+.*', ''))\n",
    "laptop = laptop.withColumn('cpu_type', f.regexp_replace(laptop['cpu_type'], '[-].*', ''))\n",
    "laptop = laptop.withColumn('cpu_type', f.rtrim(f.regexp_replace(laptop['cpu_type'], '[A-Z]\\d+.*', '')))\n",
    "\n",
    "laptop.groupBy('cpu_type').count().sort(f.col('count').desc()).show(truncate = False)"
   ]
  },
  {
   "source": [
    "We will continue by extracting the CPU clock speed."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------+--------------------+-------------+---------+\n|laptop_ID|                 Cpu|     cpu_type|cpu_clock|\n+---------+--------------------+-------------+---------+\n|        1|Intel Core i5 2.3GHz|Intel Core i5|      2.3|\n|        2|Intel Core i5 1.8GHz|Intel Core i5|      1.8|\n|        3|Intel Core i5 720...|Intel Core i5|      2.5|\n|        4|Intel Core i7 2.7GHz|Intel Core i7|      2.7|\n|        5|Intel Core i5 3.1GHz|Intel Core i5|      3.1|\n|        6|AMD A9-Series 942...|          AMD|      3.0|\n|        7|Intel Core i7 2.2GHz|Intel Core i7|      2.2|\n|        8|Intel Core i5 1.8GHz|Intel Core i5|      1.8|\n|        9|Intel Core i7 855...|Intel Core i7|      1.8|\n|       10|Intel Core i5 825...|Intel Core i5|      1.6|\n+---------+--------------------+-------------+---------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "# CPU Clock Speed\n",
    "laptop = laptop.withColumn('cpu_clock', f.regexp_extract(laptop['Cpu'], ' \\d+GHz|\\d+[.]\\d+.*GHz', 0))\n",
    "laptop = laptop.withColumn('cpu_clock', f.regexp_replace(laptop['cpu_clock'], 'GHz', '').cast(DoubleType()))\n",
    "\n",
    "laptop.select(['laptop_ID', 'Cpu', 'cpu_type', 'cpu_clock']).show(10)"
   ]
  },
  {
   "source": [
    "### Transforming GPU\n",
    "\n",
    "GPU is also an important part, especially for people who want to look for better gaming experience. Since there are a lot of GPU variant, we will only extract the first 2 words from the GPU type. For example, `Intel Iris` or `Intel HD`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------+----------------------------+--------------+\n|laptop_ID|Gpu                         |gpu_type      |\n+---------+----------------------------+--------------+\n|1        |Intel Iris Plus Graphics 640|Intel Iris    |\n|2        |Intel HD Graphics 6000      |Intel HD      |\n|3        |Intel HD Graphics 620       |Intel HD      |\n|4        |AMD Radeon Pro 455          |AMD Radeon    |\n|5        |Intel Iris Plus Graphics 650|Intel Iris    |\n|6        |AMD Radeon R5               |AMD Radeon    |\n|7        |Intel Iris Pro Graphics     |Intel Iris    |\n|8        |Intel HD Graphics 6000      |Intel HD      |\n|9        |Nvidia GeForce MX150        |Nvidia GeForce|\n|10       |Intel UHD Graphics 620      |Intel UHD     |\n+---------+----------------------------+--------------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "laptop = laptop.withColumn('gpu_type', f.concat( f.split(laptop['Gpu'], ' ').getItem(0) , f.lit(' '), f.split(laptop['Gpu'], ' ').getItem(1)) )\n",
    "\n",
    "laptop.select(['laptop_ID', 'Gpu', 'gpu_type']).show(10, truncate = False)"
   ]
  },
  {
   "source": [
    "### Transforming Screen Resolution\n",
    "\n",
    "Next, we will extract information from the `ScreenResolution`. If the laptop has touchscreen feature, we will give value of `1`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------+----------------------------------+------------+\n|laptop_ID|ScreenResolution                  |touch_screen|\n+---------+----------------------------------+------------+\n|1        |IPS Panel Retina Display 2560x1600|0           |\n|2        |1440x900                          |0           |\n|3        |Full HD 1920x1080                 |0           |\n|4        |IPS Panel Retina Display 2880x1800|0           |\n|5        |IPS Panel Retina Display 2560x1600|0           |\n|6        |1366x768                          |0           |\n|7        |IPS Panel Retina Display 2880x1800|0           |\n|8        |1440x900                          |0           |\n|9        |Full HD 1920x1080                 |0           |\n|10       |IPS Panel Full HD 1920x1080       |0           |\n+---------+----------------------------------+------------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "laptop = laptop.withColumn('touch_screen', f.when( f.col('ScreenResolution').contains('Touchscreen'), 1).otherwise(0))\n",
    "\n",
    "laptop.select(['laptop_ID', 'ScreenResolution', 'touch_screen']).show(10, truncate = False)"
   ]
  },
  {
   "source": [
    "Now we will extract the screen width. A special is when the screen resolution is in 4K, where the dimension is not explicitly stated. To counter such problem, we will assume that for all laptop with 4K resolution has aspect ratio of 16:9 or 3840x2160, which is the most common 4K resolution according to [PC Monitors](https://pcmonitors.info/articles/the-4k-uhd-3840-x-2160-experience/)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------+----------------------------------+------------+------------+\n|laptop_ID|ScreenResolution                  |touch_screen|screen_width|\n+---------+----------------------------------+------------+------------+\n|1        |IPS Panel Retina Display 2560x1600|0           |2560.0      |\n|2        |1440x900                          |0           |1440.0      |\n|3        |Full HD 1920x1080                 |0           |1920.0      |\n|4        |IPS Panel Retina Display 2880x1800|0           |2880.0      |\n|5        |IPS Panel Retina Display 2560x1600|0           |2560.0      |\n|6        |1366x768                          |0           |1366.0      |\n|7        |IPS Panel Retina Display 2880x1800|0           |2880.0      |\n|8        |1440x900                          |0           |1440.0      |\n|9        |Full HD 1920x1080                 |0           |1920.0      |\n|10       |IPS Panel Full HD 1920x1080       |0           |1920.0      |\n+---------+----------------------------------+------------+------------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "laptop = laptop.withColumn('screen_width', f.regexp_extract(laptop['ScreenResolution'], '\\d+.*?x',0))\n",
    "laptop = laptop.withColumn('screen_width', f.regexp_replace(laptop['screen_width'], 'x', ''))\n",
    "laptop = laptop.withColumn('screen_width', f.when( f.col('screen_width').contains('4K'), '3840').otherwise(f.col('screen_width')).\\\n",
    "    cast(DoubleType()))\n",
    "\n",
    "laptop.select(['laptop_ID', 'ScreenResolution', 'touch_screen', 'screen_width']).show(10, truncate = False)"
   ]
  },
  {
   "source": [
    "We will continue extracting the height resolution of the screen."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------+----------------------------------+------------+------------+-------------+\n|laptop_ID|ScreenResolution                  |touch_screen|screen_width|screen_height|\n+---------+----------------------------------+------------+------------+-------------+\n|1        |IPS Panel Retina Display 2560x1600|0           |2560.0      |1600.0       |\n|2        |1440x900                          |0           |1440.0      |900.0        |\n|3        |Full HD 1920x1080                 |0           |1920.0      |1080.0       |\n|4        |IPS Panel Retina Display 2880x1800|0           |2880.0      |1800.0       |\n|5        |IPS Panel Retina Display 2560x1600|0           |2560.0      |1600.0       |\n|6        |1366x768                          |0           |1366.0      |768.0        |\n|7        |IPS Panel Retina Display 2880x1800|0           |2880.0      |1800.0       |\n|8        |1440x900                          |0           |1440.0      |900.0        |\n|9        |Full HD 1920x1080                 |0           |1920.0      |1080.0       |\n|10       |IPS Panel Full HD 1920x1080       |0           |1920.0      |1080.0       |\n+---------+----------------------------------+------------+------------+-------------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "laptop = laptop.withColumn('screen_height', f.regexp_extract(laptop['ScreenResolution'], 'x.*\\d+',0))\n",
    "laptop = laptop.withColumn('screen_height', f.regexp_replace(laptop['screen_height'], 'x', ''))\n",
    "laptop = laptop.withColumn('screen_height', f.when( f.col('screen_height').contains('4K'), '2160').otherwise(f.col('screen_height')).\\\n",
    "    cast(DoubleType()))\n",
    "\n",
    "laptop.select(['laptop_ID', 'ScreenResolution', 'touch_screen', 'screen_width', 'screen_height']).show(10, truncate = False)"
   ]
  },
  {
   "source": [
    "We will also extract the type of the monitor. If an observation doesn't have any type of monitor and only show the screen resolution, we will fill the monitor type with `others`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------------------------+-----+\n|monitor_type            |count|\n+------------------------+-----+\n|Full HD                 |555  |\n|                        |364  |\n|IPS Panel Full HD       |288  |\n|IPS Panel               |49   |\n|Quad HD+                |19   |\n|IPS Panel Retina Display|17   |\n|IPS Panel Quad HD+      |11   |\n+------------------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "laptop = laptop.withColumn('monitor_type', f.regexp_replace(laptop['ScreenResolution'], '\\d+.*', ''))\n",
    "laptop = laptop.withColumn('monitor_type', f.regexp_replace(laptop['monitor_type'], 'Touchscreen', ''))\n",
    "laptop = laptop.withColumn('monitor_type', f.trim(f.regexp_replace(laptop['monitor_type'], '[/]', '')))\n",
    "\n",
    "laptop.groupBy('monitor_type').count().sort(f.col('count').desc()).show(truncate = False)"
   ]
  },
  {
   "source": [
    "As we can see, there is a lot of laptop with no specified monitor type. We will use `others` to fill the empty monitor type value."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop = laptop.withColumn('monitor_type', f.when(f.col('monitor_type') == '', 'others').otherwise(f.col('monitor_type')))"
   ]
  },
  {
   "source": [
    "To simplify the dataset, we will drop some columns that are not necessary for building the model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------+------+---+----------+------+-----------+-----+-----+-----+-------------+---------+--------------+------------+------------+-------------+--------------------+\n|Company|Inches|Ram|     OpSys|Weight|Price_euros|  ssd|  hdd|flash|     cpu_type|cpu_clock|      gpu_type|touch_screen|screen_width|screen_height|        monitor_type|\n+-------+------+---+----------+------+-----------+-----+-----+-----+-------------+---------+--------------+------------+------------+-------------+--------------------+\n|  Apple|  13.3|  8|     macOS|  1.37|    1339.69|128.0|  0.0|  0.0|Intel Core i5|      2.3|    Intel Iris|           0|      2560.0|       1600.0|IPS Panel Retina ...|\n|  Apple|  13.3|  8|     macOS|  1.34|     898.94|  0.0|  0.0|128.0|Intel Core i5|      1.8|      Intel HD|           0|      1440.0|        900.0|              others|\n|     HP|  15.6|  8|     No OS|  1.86|      575.0|256.0|  0.0|  0.0|Intel Core i5|      2.5|      Intel HD|           0|      1920.0|       1080.0|             Full HD|\n|  Apple|  15.4| 16|     macOS|  1.83|    2537.45|512.0|  0.0|  0.0|Intel Core i7|      2.7|    AMD Radeon|           0|      2880.0|       1800.0|IPS Panel Retina ...|\n|  Apple|  13.3|  8|     macOS|  1.37|     1803.6|256.0|  0.0|  0.0|Intel Core i5|      3.1|    Intel Iris|           0|      2560.0|       1600.0|IPS Panel Retina ...|\n|   Acer|  15.6|  4|Windows 10|   2.1|      400.0|  0.0|500.0|  0.0|          AMD|      3.0|    AMD Radeon|           0|      1366.0|        768.0|              others|\n|  Apple|  15.4| 16|  Mac OS X|  2.04|    2139.97|  0.0|  0.0|256.0|Intel Core i7|      2.2|    Intel Iris|           0|      2880.0|       1800.0|IPS Panel Retina ...|\n|  Apple|  13.3|  8|     macOS|  1.34|     1158.7|  0.0|  0.0|256.0|Intel Core i5|      1.8|      Intel HD|           0|      1440.0|        900.0|              others|\n|   Asus|  14.0| 16|Windows 10|   1.3|     1495.0|512.0|  0.0|  0.0|Intel Core i7|      1.8|Nvidia GeForce|           0|      1920.0|       1080.0|             Full HD|\n|   Acer|  14.0|  8|Windows 10|   1.6|      770.0|256.0|  0.0|  0.0|Intel Core i5|      1.6|     Intel UHD|           0|      1920.0|       1080.0|   IPS Panel Full HD|\n+-------+------+---+----------+------+-----------+-----+-----+-----+-------------+---------+--------------+------------+------------+-------------+--------------------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "laptop_clean = laptop.drop('laptop_ID', 'Product', 'TypeName', 'ScreenResolution', 'Cpu', 'Memory', 'Gpu')\n",
    "\n",
    "laptop_clean.show(10)"
   ]
  },
  {
   "source": [
    "## One-Hot Encoding\n",
    "\n",
    "Before we split the data into data training and data testing, now we will convert the categorical variable into dummy features by using one-hot encoding so that it can be processed by the machine learing model.\n",
    "\n",
    "The following columns will be transformed:\n",
    "\n",
    "- cpu_type\n",
    "- gpu_type\n",
    "- OpSys (OS)\n",
    "- Company\n",
    "- Monitor Type\n",
    "\n",
    "First, we will convert each category into integer index. For example, `Intel Core i7` will be 0, `Intel Core i5` will be 1, `AMD` will be 4, etc."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------------+---------+\n|     cpu_type|cpu_index|\n+-------------+---------+\n|Intel Core i5|      1.0|\n|Intel Core i5|      1.0|\n|Intel Core i5|      1.0|\n|Intel Core i7|      0.0|\n|Intel Core i5|      1.0|\n|          AMD|      4.0|\n|Intel Core i7|      0.0|\n|Intel Core i5|      1.0|\n|Intel Core i7|      0.0|\n|Intel Core i5|      1.0|\n+-------------+---------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "cpu_str_indexer = StringIndexer(inputCol='cpu_type', outputCol = 'cpu_index').fit(laptop_clean)\n",
    "\n",
    "laptop_clean = cpu_str_indexer.transform(laptop_clean)\n",
    "\n",
    "laptop_clean.select(['cpu_type','cpu_index']).show(10) "
   ]
  },
  {
   "source": [
    "After the category has been tranfomed into index, now we can continue by doing one-hot encoding. The output is an array. For example, `(18,[1],[1.0])` means that there is 18 elements in the array and on index 1 the value is 1.0 while the other is 0."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------------+---------+--------------+\n|     cpu_type|cpu_index|   cpu_encoded|\n+-------------+---------+--------------+\n|Intel Core i5|      1.0|(18,[1],[1.0])|\n|Intel Core i5|      1.0|(18,[1],[1.0])|\n|Intel Core i5|      1.0|(18,[1],[1.0])|\n|Intel Core i7|      0.0|(18,[0],[1.0])|\n|Intel Core i5|      1.0|(18,[1],[1.0])|\n|          AMD|      4.0|(18,[4],[1.0])|\n|Intel Core i7|      0.0|(18,[0],[1.0])|\n|Intel Core i5|      1.0|(18,[1],[1.0])|\n|Intel Core i7|      0.0|(18,[0],[1.0])|\n|Intel Core i5|      1.0|(18,[1],[1.0])|\n+-------------+---------+--------------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "cpu_encoder = OneHotEncoder(inputCol = 'cpu_index', outputCol='cpu_encoded', dropLast = False).fit(laptop_clean)\n",
    "\n",
    "laptop_clean = cpu_encoder.transform(laptop_clean)\n",
    "\n",
    "laptop_clean.select(['cpu_type','cpu_index', 'cpu_encoded']).show(10) "
   ]
  },
  {
   "source": [
    "We will continue by transforming the rest of the categorical variables."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU \n",
    "gpu_str_indexer = StringIndexer(inputCol='gpu_type', outputCol = 'gpu_index').fit(laptop_clean)\n",
    "laptop_clean = gpu_str_indexer.transform(laptop_clean)\n",
    "\n",
    "gpu_encoder = OneHotEncoder(inputCol = 'gpu_index', outputCol='gpu_encoded', dropLast = False).fit(laptop_clean)\n",
    "laptop_clean = gpu_encoder.transform(laptop_clean)\n",
    "\n",
    "# OS\n",
    "os_str_indexer = StringIndexer(inputCol='OpSys', outputCol = 'os_index').fit(laptop_clean)\n",
    "laptop_clean = os_str_indexer.transform(laptop_clean)\n",
    "\n",
    "os_encoder = OneHotEncoder(inputCol = 'os_index', outputCol='os_encoded', dropLast = False).fit(laptop_clean)\n",
    "laptop_clean = os_encoder.transform(laptop_clean)\n",
    "\n",
    "# Company\n",
    "comp_str_indexer = StringIndexer(inputCol='Company', outputCol = 'comp_index').fit(laptop_clean)\n",
    "laptop_clean = comp_str_indexer.transform(laptop_clean)\n",
    "\n",
    "comp_encoder = OneHotEncoder(inputCol = 'comp_index', outputCol='comp_encoded', dropLast = False).fit(laptop_clean)\n",
    "laptop_clean = comp_encoder.transform(laptop_clean)\n",
    "\n",
    "# Monitor Type\n",
    "mon_str_indexer = StringIndexer(inputCol='monitor_type', outputCol = 'mon_index').fit(laptop_clean)\n",
    "laptop_clean = mon_str_indexer.transform(laptop_clean)\n",
    "\n",
    "mon_encoder = OneHotEncoder(inputCol = 'mon_index', outputCol='mon_encoded', dropLast = False).fit(laptop_clean)\n",
    "laptop_clean = mon_encoder.transform(laptop_clean)"
   ]
  },
  {
   "source": [
    "Finally, we will drop unnecessary column."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+---+------+-----------+-----+---+-----+---------+------------+------------+-------------+--------------+--------------+--------+-------------+--------------+-------------+\n|Inches|Ram|Weight|Price_euros|  ssd|hdd|flash|cpu_clock|touch_screen|screen_width|screen_height|   cpu_encoded|   gpu_encoded|os_index|   os_encoded|  comp_encoded|  mon_encoded|\n+------+---+------+-----------+-----+---+-----+---------+------------+------------+-------------+--------------+--------------+--------+-------------+--------------+-------------+\n|  13.3|  8|  1.37|    1339.69|128.0|0.0|  0.0|      2.3|           0|      2560.0|       1600.0|(18,[1],[1.0])|(12,[5],[1.0])|     5.0|(9,[5],[1.0])|(19,[7],[1.0])|(7,[5],[1.0])|\n|  13.3|  8|  1.34|     898.94|  0.0|0.0|128.0|      1.8|           0|      1440.0|        900.0|(18,[1],[1.0])|(12,[0],[1.0])|     5.0|(9,[5],[1.0])|(19,[7],[1.0])|(7,[1],[1.0])|\n|  15.6|  8|  1.86|      575.0|256.0|0.0|  0.0|      2.5|           0|      1920.0|       1080.0|(18,[1],[1.0])|(12,[0],[1.0])|     1.0|(9,[1],[1.0])|(19,[2],[1.0])|(7,[0],[1.0])|\n|  15.4| 16|  1.83|    2537.45|512.0|0.0|  0.0|      2.7|           0|      2880.0|       1800.0|(18,[0],[1.0])|(12,[2],[1.0])|     5.0|(9,[5],[1.0])|(19,[7],[1.0])|(7,[5],[1.0])|\n|  13.3|  8|  1.37|     1803.6|256.0|0.0|  0.0|      3.1|           0|      2560.0|       1600.0|(18,[1],[1.0])|(12,[5],[1.0])|     5.0|(9,[5],[1.0])|(19,[7],[1.0])|(7,[5],[1.0])|\n+------+---+------+-----------+-----+---+-----+---------+------------+------------+-------------+--------------+--------------+--------+-------------+--------------+-------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "laptop_final = laptop_clean.drop('Company', 'OpSys', 'cpu_type', 'gpu_type', 'monitor_type', 'cpu_index', 'gpu_index', 'mon_index', 'comp_index')\n",
    "\n",
    "laptop_final.show(5)"
   ]
  },
  {
   "source": [
    "Finally, we will create an assembler to join the feature together into a single array. First, we define which column will be the feature."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col = laptop_final.columns\n",
    "feature_col.remove('Price_euros')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------+-------------------------------------------------------------------------------------------------------+\n|Price_euros|features                                                                                               |\n+-----------+-------------------------------------------------------------------------------------------------------+\n|1339.69    |(76,[0,1,2,3,6,8,9,11,33,40,46,57,74],[13.3,8.0,1.37,128.0,2.3,2560.0,1600.0,1.0,1.0,5.0,1.0,1.0,1.0]) |\n|898.94     |(76,[0,1,2,5,6,8,9,11,28,40,46,57,70],[13.3,8.0,1.34,128.0,1.8,1440.0,900.0,1.0,1.0,5.0,1.0,1.0,1.0])  |\n|575.0      |(76,[0,1,2,3,6,8,9,11,28,40,42,52,69],[15.6,8.0,1.86,256.0,2.5,1920.0,1080.0,1.0,1.0,1.0,1.0,1.0,1.0]) |\n|2537.45    |(76,[0,1,2,3,6,8,9,10,30,40,46,57,74],[15.4,16.0,1.83,512.0,2.7,2880.0,1800.0,1.0,1.0,5.0,1.0,1.0,1.0])|\n|1803.6     |(76,[0,1,2,3,6,8,9,11,33,40,46,57,74],[13.3,8.0,1.37,256.0,3.1,2560.0,1600.0,1.0,1.0,5.0,1.0,1.0,1.0]) |\n|400.0      |(76,[0,1,2,4,6,8,9,14,30,41,54,70],[15.6,4.0,2.1,500.0,3.0,1366.0,768.0,1.0,1.0,1.0,1.0,1.0])          |\n|2139.97    |(76,[0,1,2,5,6,8,9,10,33,40,47,57,74],[15.4,16.0,2.04,256.0,2.2,2880.0,1800.0,1.0,1.0,6.0,1.0,1.0,1.0])|\n|1158.7     |(76,[0,1,2,5,6,8,9,11,28,40,46,57,70],[13.3,8.0,1.34,256.0,1.8,1440.0,900.0,1.0,1.0,5.0,1.0,1.0,1.0])  |\n|1495.0     |(76,[0,1,2,3,6,8,9,10,29,41,53,69],[14.0,16.0,1.3,512.0,1.8,1920.0,1080.0,1.0,1.0,1.0,1.0,1.0])        |\n|770.0      |(76,[0,1,2,3,6,8,9,11,31,41,54,71],[14.0,8.0,1.6,256.0,1.6,1920.0,1080.0,1.0,1.0,1.0,1.0,1.0])         |\n+-----------+-------------------------------------------------------------------------------------------------------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "laptop_assembler = VectorAssembler(inputCols = feature_col, outputCol = 'features')\n",
    "laptop_ml = laptop_assembler.transform(laptop_final).select('Price_euros', 'features')\n",
    "\n",
    "laptop_ml.show(10, truncate = False)"
   ]
  },
  {
   "source": [
    "The next thing is splitting the data into training and testing dataset. We will use 20% of the data as the testing set."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of Training Set: 1041\n",
      "Number of Testing Set: 262\n"
     ]
    }
   ],
   "source": [
    "(train_data, test_data) = laptop_ml.randomSplit([0.8,0.2], seed = 123)\n",
    "\n",
    "print(\"Number of Training Set: \" + str(train_data.count()))\n",
    "print(\"Number of Testing Set: \" + str(test_data.count()))"
   ]
  },
  {
   "source": [
    "Now we will normalize all features so that they will have the same scale."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scaler = StandardScaler(inputCol = 'features', outputCol = 'scaled_feature').fit(train_data)\n",
    "\n",
    "train_data = feature_scaler.transform(train_data)\n",
    "test_data = feature_scaler.transform(test_data)"
   ]
  },
  {
   "source": [
    "## Model Fitting\n",
    "\n",
    "We will start building machine learning model. We will build the following model and compare the predictive performance:\n",
    "\n",
    "- Linear Regression\n",
    "- Lasso Regression \n",
    "- Ridge Regression \n",
    "- Elastic Net Regression\n",
    "\n",
    "### Linear Regression\n",
    "\n",
    "First, we fit the OLS (Ordinary Least Square) linear regression into the training dataset. OLS will try to find the best coefficient for the intercept and each feature by minimizing the **Sum of Squared Error** as the lost function.\n",
    "\n",
    "$$\n",
    "SSE = \\Sigma_{i=1}^n (y - \\overline y)^2\n",
    "$$\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = LinearRegression(featuresCol = 'scaled_feature', labelCol = 'Price_euros').fit(train_data)"
   ]
  },
  {
   "source": [
    "Let's check the estimate coefficients for each features."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Coefficients\n",
       "0    -104.784682\n",
       "1     231.813028\n",
       "2     154.769230\n",
       "3     172.472791\n",
       "4      16.840297\n",
       "..           ...\n",
       "71      9.607375\n",
       "72     13.593014\n",
       "73      5.798212\n",
       "74      8.850902\n",
       "75    -16.326668\n",
       "\n",
       "[76 rows x 1 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Coefficients</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-104.784682</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>231.813028</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>154.769230</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>172.472791</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>16.840297</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>9.607375</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>13.593014</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>5.798212</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>8.850902</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>-16.326668</td>\n    </tr>\n  </tbody>\n</table>\n<p>76 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "pd.DataFrame({'Coefficients' : list(linear_model.coefficients)})"
   ]
  },
  {
   "source": [
    "#### Model Evaluation\n",
    "\n",
    "Let's check the prediction performance of the linear regression. We will use the R-squared (R2 Score) and the error measured by Root Mean Squared Error (RMSE). RMSE is a good measure to evaluate regression problem because they punish model more if there are observations that has high error."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------+--------------------+--------------------+------------------+\n|Price_euros|            features|      scaled_feature|        prediction|\n+-----------+--------------------+--------------------+------------------+\n|      196.0|(76,[0,1,2,5,6,8,...|(76,[0,1,2,5,6,8,...|395.10240043764685|\n|      209.0|(76,[0,1,2,3,6,8,...|(76,[0,1,2,3,6,8,...| 177.1926571090077|\n|      229.0|(76,[0,1,2,3,6,8,...|(76,[0,1,2,3,6,8,...| 389.6019183241022|\n|      229.0|(76,[0,1,2,5,6,8,...|(76,[0,1,2,5,6,8,...| 260.6918663586507|\n|      245.0|(76,[0,1,2,5,6,8,...|(76,[0,1,2,5,6,8,...| 272.6768573416165|\n|      249.0|(76,[0,1,2,5,6,8,...|(76,[0,1,2,5,6,8,...| 303.0795790008959|\n|      265.0|(76,[0,1,2,3,6,8,...|(76,[0,1,2,3,6,8,...| 351.6796525465811|\n|      265.0|(76,[0,1,2,4,6,8,...|(76,[0,1,2,4,6,8,...| 475.5192679670997|\n|     270.62|(76,[0,1,2,3,6,8,...|(76,[0,1,2,3,6,8,...|121.79844227990338|\n|      272.0|(76,[0,1,2,4,6,8,...|(76,[0,1,2,4,6,8,...| 162.5798409150588|\n+-----------+--------------------+--------------------+------------------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "pred_test = linear_model.transform(test_data)\n",
    "\n",
    "pred_test.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "R-Squared: 0.760\n",
      "RMSE: 320.6822\n"
     ]
    }
   ],
   "source": [
    "print(\"R-Squared: {:.3f}\".format(RegressionEvaluator(labelCol='Price_euros', metricName='r2').evaluate(pred_test)))\n",
    "print(\"RMSE: {:.4f}\".format(RegressionEvaluator(labelCol='Price_euros', metricName='rmse').evaluate(pred_test)))"
   ]
  },
  {
   "source": [
    "We can compare the RMSE with the standard deviation of the price variable from the testing dataset. According to [Bowles](https://www.amazon.com/Machine-Learning-Spark-Python-Techniques/dp/1119561930), if the RMSE is lower than the standard deviation, then we can conclude that the model has a good performance. A good model should, on average, have better predictions than the naive estimate of the mean for all predictions."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------------------------+\n|Price Standard Deviation|\n+------------------------+\n|                656.0568|\n+------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "test_data.select(f.format_number(f.stddev('Price_euros'),4).alias('Price Standard Deviation')).show()"
   ]
  },
  {
   "source": [
    "### Lasso Regression\n",
    "\n",
    "Lasso regression is a variant of linear regression that comes with a penalty on the loss function to help the model do regularization and reduce the model variance. Model with less variance will be better at predicing new data. The idea is to induce the penalty against complexity by adding the regularization term such as that with increasing value of regularization parameter, the weights get reduced (and, hence penalty induced).\n",
    "\n",
    "As you may have learn before, linear regression try to get the best estimate value for the model intercept and slope for each feature by minimizing the Sum of Squared Error (SSE). \n",
    "\n",
    "$$\n",
    "SSE = \\Sigma_i^N (y_i - \\hat y_i)^2\n",
    "$$\n",
    "\n",
    "Lasso Regression will add an L1 penalty with $\\lambda$ constant to the loss function. If $\\lambda$ equals zero, then the lasso regression become identical with the ordinary linear regression.\n",
    "\n",
    "$$\n",
    "SSE = \\Sigma_{i=1}^N (y_i - \\hat y_i)^2 + \\lambda\\ \\Sigma_{j=1}^n |\\beta_j|\n",
    "$$\n",
    "\n",
    "The benefit of using Lasso is that it can function as a feature selection method. This model will shrink and sometimes remove features so that we only have the features that affect the target data. To fit a Lasso model, we need to scale all features. The features need to have the same scale so that the coefficient values are chosen based only on which attribute is most useful, not on the basis of which one has the most favorable scale.\n",
    "\n",
    "The first thing we need to do to build a Lasso model is by choosing the appropriate value of $\\lambda$ as the penalty constant. pyspark has build in estimator can help us get the optimal hyper-parameter (in this case, $\\lambda$) with Cross-Validation method with grid search to evaluate the model. For a Lasso model, the `elasticNetParam` must be set to 1.\n",
    "\n",
    "In the following step, we set 10-Fold Cross-Validation method to fit and evaluate the data and try 1000 different $\\lambda$ as the penalty constant. The model will give us the best \\$lambda$ to choose."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Lambda: 2.8283\n"
     ]
    }
   ],
   "source": [
    "# Set Lasso with elasticNetParam = 1\n",
    "lr = LinearRegression(elasticNetParam = 1, featuresCol = 'scaled_feature', labelCol = 'Price_euros') # Lasso\n",
    "\n",
    "# Set the value of lambda to tune\n",
    "paramgrid = ParamGridBuilder().addGrid(lr.regParam, np.linspace(0, 10, 100)).build()\n",
    "\n",
    "# Set error metric to evaluate\n",
    "reg_evaluator = RegressionEvaluator(labelCol='Price_euros', metricName='rmse')\n",
    "\n",
    "# Set Cross Validation setting\n",
    "lasso_cv = CrossValidator(estimator = lr, estimatorParamMaps = paramgrid, evaluator = reg_evaluator, numFolds = 10, parallelism = 4)\n",
    "\n",
    "# Model Fitting\n",
    "lasso_cv = lasso_cv.fit(train_data)\n",
    "\n",
    "print(\"Best Lambda: {:.4f}\".format(lasso_cv.bestModel.getRegParam()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "R-Squared: 0.761\n",
      "RMSE: 320.2203\n"
     ]
    }
   ],
   "source": [
    "pred_lasso = lasso_cv.transform(test_data)\n",
    "\n",
    "print(\"R-Squared: {:.3f}\".format(RegressionEvaluator(labelCol='Price_euros', metricName='r2').evaluate(pred_lasso)))\n",
    "print(\"RMSE: {:.4f}\".format(RegressionEvaluator(labelCol='Price_euros', metricName='rmse').evaluate(pred_lasso)))"
   ]
  },
  {
   "source": [
    "### Ridge Regression\n",
    "\n",
    "Ridge regression is similar with Lasso by creating a penalty toward the lost function. The difference is that the ridge regression will square the coefficient instead of making it absolute for the penalty. Larger value of $\\lambda$ will make the coefficient to be smaller, but never reach to 0 in Ridge regression.\n",
    "\n",
    "$$\n",
    "SSE = \\Sigma_{i=1}^N (y_i - \\hat y_i)^2 + \\lambda\\ \\Sigma_{j=1}^n \\beta_j^2\n",
    "$$\n",
    "\n",
    "In the following process, I set the possible alpha values from 0.0001 to 100 with different steps."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Lambda: 64.0000\n"
     ]
    }
   ],
   "source": [
    "# Set Ridge with elasticNetParam = 0\n",
    "lr = LinearRegression(elasticNetParam = 0, featuresCol = 'scaled_feature', labelCol = 'Price_euros') # Lasso\n",
    "\n",
    "# Set the value of lambda to tune\n",
    "lambda_range = [1e-4, 1e-3, 1e-2, 0.1, 1]\n",
    "lambda_range.extend(np.arange(10, 100, 1))\n",
    "paramgrid = ParamGridBuilder().addGrid(lr.regParam, lambda_range).build()\n",
    "\n",
    "# Set error metric to evaluate\n",
    "reg_evaluator = RegressionEvaluator(labelCol='Price_euros', metricName='rmse')\n",
    "\n",
    "# Set Cross Validation setting\n",
    "ridge_cv = CrossValidator(estimator = lr, estimatorParamMaps = paramgrid, evaluator = reg_evaluator, numFolds = 10, parallelism = 4)\n",
    "\n",
    "# Model Fitting\n",
    "ridge_cv = ridge_cv.fit(train_data)\n",
    "\n",
    "print(\"Best Lambda: {:.4f}\".format(ridge_cv.bestModel.getRegParam()))"
   ]
  },
  {
   "source": [
    "Let's evaluate the model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "R-Squared: 0.768\n",
      "RMSE: 315.3129\n"
     ]
    }
   ],
   "source": [
    "pred_ridge = ridge_cv.transform(test_data)\n",
    "\n",
    "print(\"R-Squared: {:.3f}\".format(RegressionEvaluator(labelCol='Price_euros', metricName='r2').evaluate(pred_ridge)))\n",
    "print(\"RMSE: {:.4f}\".format(RegressionEvaluator(labelCol='Price_euros', metricName='rmse').evaluate(pred_ridge)))"
   ]
  },
  {
   "source": [
    "### Elastic Net Regression\n",
    "\n",
    "Elastic Net combine both L1 penalty and the L2 penalty into a single formula. This combination allows for learning a sparse model where few of the weights are non-zero like Lasso, while still maintaining the regularization properties of Ridge.\n",
    "\n",
    "$$\n",
    "SSE = \\Sigma_{i=1}^N (y_i - \\hat y_i)^2 + + \\lambda\\ \\alpha\\ \\Sigma_{j=1}^n |\\beta_j| + \\lambda\\ (1-\\alpha)\\ \\frac{1}{2} \\Sigma_{j=1}^n \\beta_j^2\n",
    "$$\n",
    "\n",
    "Where $\\lambda$ is set by `regParam` and $\\alpha$ is set by `elasticNetParam` in pyspark. First, we will try to balance the L1 and the L2 penalty by using the `elasticNetParam` = 0.5"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Lambda: 10.0000\nAlpha: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Set Elastic Net alpha to 0.5\n",
    "lr = LinearRegression(elasticNetParam = 0.5, featuresCol = 'scaled_feature', labelCol = 'Price_euros') # Lasso\n",
    "\n",
    "# Set the value of lambda to tune\n",
    "lambda_range = [1e-4, 1e-3, 1e-2, 0.1, 1]\n",
    "lambda_range.extend(np.arange(10, 100, 1))\n",
    "paramgrid = ParamGridBuilder().addGrid(lr.regParam, lambda_range).build()\n",
    "\n",
    "# Set error metric to evaluate\n",
    "reg_evaluator = RegressionEvaluator(labelCol='Price_euros', metricName='rmse')\n",
    "\n",
    "# Set Cross Validation setting\n",
    "elastic_cv = CrossValidator(estimator = lr, estimatorParamMaps = paramgrid, evaluator = reg_evaluator, numFolds = 10, parallelism = 4)\n",
    "\n",
    "# Model Fitting\n",
    "elastic_cv = elastic_cv.fit(train_data)\n",
    "\n",
    "print(\"Best Lambda: {:.4f}\".format(elastic_cv.bestModel.getRegParam()))\n",
    "print(\"Alpha: 0.5\")"
   ]
  },
  {
   "source": [
    "Let's evaluate the model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "R-Squared: 0.760\n",
      "RMSE: 320.9835\n"
     ]
    }
   ],
   "source": [
    "pred_elastic = elastic_cv.transform(test_data)\n",
    "\n",
    "print(\"R-Squared: {:.3f}\".format(RegressionEvaluator(labelCol='Price_euros', metricName='r2').evaluate(pred_elastic)))\n",
    "print(\"RMSE: {:.4f}\".format(RegressionEvaluator(labelCol='Price_euros', metricName='rmse').evaluate(pred_elastic)))"
   ]
  },
  {
   "source": [
    "We can put multiple `elasticNetParam` to find the best ratio between the L1 and the L2 penalty."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Lambda: 35.0000\nBest Alpha: 0.0500\n"
     ]
    }
   ],
   "source": [
    "# Set Basic Linear Model\n",
    "lr = LinearRegression(featuresCol = 'scaled_feature', labelCol = 'Price_euros') # Lasso\n",
    "\n",
    "# Set the value of lambda and alpha to tune\n",
    "lambda_range = [1e-4, 1e-3, 1e-2, 0.1, 1]\n",
    "lambda_range.extend(np.arange(10, 100, 1))\n",
    "\n",
    "alpha_range = [0.05, 0.1, 0.2, 0.3, 0.7, 0.8, 0.9, 0.95]\n",
    "\n",
    "paramgrid = ParamGridBuilder().addGrid(lr.regParam, lambda_range).addGrid(lr.elasticNetParam, alpha_range).build()\n",
    "\n",
    "# Set error metric to evaluate\n",
    "reg_evaluator = RegressionEvaluator(labelCol='Price_euros', metricName='rmse')\n",
    "\n",
    "# Set Cross Validation setting\n",
    "elastic_cv = CrossValidator(estimator = lr, estimatorParamMaps = paramgrid, evaluator = reg_evaluator, numFolds = 10, parallelism = 4)\n",
    "\n",
    "# Model Fitting\n",
    "elastic_cv = elastic_cv.fit(train_data)\n",
    "\n",
    "print(\"Best Lambda: {:.4f}\".format(elastic_cv.bestModel.getRegParam()))\n",
    "print(\"Best Alpha: {:.4f}\".format(elastic_cv.bestModel.getElasticNetParam()))"
   ]
  },
  {
   "source": [
    "Let's evaluate the model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "R-Squared: 0.765\n",
      "RMSE: 317.3814\n"
     ]
    }
   ],
   "source": [
    "pred_elastic = elastic_cv.transform(test_data)\n",
    " \n",
    "print(\"R-Squared: {:.3f}\".format(RegressionEvaluator(labelCol='Price_euros', metricName='r2').evaluate(pred_elastic)))\n",
    "print(\"RMSE: {:.4f}\".format(RegressionEvaluator(labelCol='Price_euros', metricName='rmse').evaluate(pred_elastic)))"
   ]
  },
  {
   "source": [
    "# Conclusion\n",
    "\n",
    "Based on our result, all regularization method works better than the vanilla linear regression, with the Ridge Regression achieve the lowest error on testing dataset. We also see that even with linear model we can achieve good result, as the RMSE of each model is still better than the standard deviation of the testing dataset. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}